{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Near-Time Gate Optimization\n",
    "This example demonstrates how to maximize gate fidelities by varying pulse parameters in near-time.\n",
    "\n",
    "This is achieved by defining an experiment from a single randomized benchmarking (RB) pulse sequence and a subsequent state measurement in real-time (RT). At the near-time (NT) level, the experiment makes use of a user callback function that obtains the value of the objective function, in this case the ORBIT fidelity, computes the parameters next optimization step, and updates and replaces the pulses that are defined by the optimized parameters.\n",
    "\n",
    "We begin with the neccessary imports. Note, that you will have to install the package `scikit-optimize` to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package installation for this notebook\n",
    "%pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from skopt import Optimizer\n",
    "\n",
    "from laboneq.simple import *\n",
    "from laboneq.contrib.example_helpers.generate_example_datastore import (\n",
    "    generate_example_datastore,\n",
    "    get_first_named_entry,\n",
    ")\n",
    "from laboneq.contrib.example_helpers.randomized_benchmarking_helper import (\n",
    "    generate_play_rb_pulses,\n",
    "    clifford_parametrized,\n",
    "    make_pauli_gate_map,\n",
    ")\n",
    "\n",
    "use_emulation = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "We define readout pulse and integration kernel as well as the mapping of the quantum gates used to construct the RB sequence from.\n",
    "We furthermore note the following\n",
    "* The Clifford gates used for randomized benchmarking are defined in terms of\n",
    "\n",
    "  $\\left\\{\\hat{I}, \\hat{X}, \\hat{Y},\\hat{X}^{1/2}, \\hat{Y}^{1/2}, \\hat{X}^{-1/2}, \\hat{Y}^{-1/2}\\right\\}$.\n",
    "\n",
    "  We will come back at them later, when defining which pulses to optimize.\n",
    "* We define RB sequences of a fixed length of `n_RB_sequence_length = 3` gates (plus a recovery gate) in this example.\n",
    "* To avoid converging to spurious local minima, a larger number of sequences (samples) are repeated, each being of the same length but contining different Clifford gates. In this example we set `n_RB_samples = 128` for the number of samples and initialize a pseudo random number generator to compose the actual gate sequence in each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qubit readout pulse\n",
    "readout_pulse = pulse_library.const(\n",
    "    uid=\"readout_pulse\",\n",
    "    length=200e-9,\n",
    "    amplitude=0.8,\n",
    ")\n",
    "\n",
    "# integration weights for qubit measurement\n",
    "integration_kernel = pulse_library.const(\n",
    "    uid=\"readout_weighting_function\",\n",
    "    length=200e-9,\n",
    "    amplitude=1.0,\n",
    ")\n",
    "\n",
    "# define the set of quantum operations for randomized benchmarking\n",
    "gate_map = make_pauli_gate_map(\n",
    "    pi_pulse_amp=0.8,\n",
    "    pi_half_pulse_amp=0.42,\n",
    "    excitation_length=64e-9,\n",
    "    pulse_factory=pulse_library.gaussian,\n",
    "    pulse_kwargs={\"sigma\": 1 / 3},\n",
    ")\n",
    "\n",
    "# length of each RB sequence, not including the recovery gate\n",
    "n_RB_sequence_length = 3\n",
    "\n",
    "# number of individual RB sequences in each pass\n",
    "n_RB_samples = 128\n",
    "\n",
    "# random number generator used to obtain the sandom sequence of RB samples\n",
    "prng = np.random.default_rng(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform optimization steps within a LabOne Q experiment, we implement an outer NT-sweep.\n",
    "The values of the sweep parameter correspond to the index of each optimization step.\n",
    "This also requires setting a maximum number of iteration steps at this point, which we define as 12 for this example.\n",
    "Note, that in actual experiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_max_steps = 12\n",
    "optimizer_sweep = LinearSweepParameter(start=0, stop=n_max_steps - 1, count=n_max_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Benchmarking Experiment\n",
    "We define the RB-waveform experiments as follows\n",
    "* A RT acquisition loop with cyclic averaging in state discrimination mode provides the average index of the measured qubit states directly. As we perform RB for a qubit in its ground state we can use this quantity directly as objective function value and optimize it, i.e. the closer this value is to 0, the higher the gate fidelities.\n",
    "* The RB sequence samples are generated by a helper function using the options defined in the previous section.\n",
    "* After the RB sequence, the qubit state is measured using the readout pulse and integration kernel defined above.\n",
    "* The RT acquisition loop is embedded in a NT sweep over iteration indices. At the end of each sweep pass, a user callback function with the label `\"next NT step\"` is called. In the next section we will discuss the definition of this function in detail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Experiment(\n",
    "    signals=[\"drive\", \"measure\", \"acquire\"],\n",
    ")\n",
    "with exp.sweep(\n",
    "    uid=\"optimizer_loop\",\n",
    "    parameter=optimizer_sweep,\n",
    "    execution_type=ExecutionType.NEAR_TIME,\n",
    "):\n",
    "    with exp.acquire_loop_rt(\n",
    "        uid=\"rb_shots\",\n",
    "        count=16,\n",
    "        averaging_mode=AveragingMode.CYCLIC,\n",
    "        acquisition_type=AcquisitionType.DISCRIMINATION,\n",
    "    ):\n",
    "        # generate multiple different RB sequences of the same length\n",
    "        for i in range(n_RB_samples):\n",
    "            # randomized benchmarking sample\n",
    "            with exp.section(\n",
    "                uid=f\"RB_sample_{i}\", play_after=f\"RB_measure_{i-1}\" if i > 0 else None\n",
    "            ):\n",
    "                generate_play_rb_pulses(\n",
    "                    exp=exp,\n",
    "                    signal=\"drive\",\n",
    "                    seq_length=n_RB_sequence_length,\n",
    "                    cliffords=clifford_parametrized,\n",
    "                    gate_map=gate_map,\n",
    "                    rng=prng,\n",
    "                )\n",
    "            # readout and data acquisition\n",
    "            with exp.section(uid=f\"RB_measure_{i}\", play_after=f\"RB_sample_{i}\"):\n",
    "                exp.measure(\n",
    "                    measure_pulse=readout_pulse,\n",
    "                    measure_signal=\"measure\",\n",
    "                    acquire_signal=\"acquire\",\n",
    "                    handle=\"rb_results\",\n",
    "                    integration_kernel=integration_kernel,\n",
    "                    reset_delay=1.0e-7,\n",
    "                )\n",
    "                exp.reserve(signal=\"drive\")\n",
    "\n",
    "    # next step: compute result, generate next optimizer step, apply new parameters\n",
    "    exp.call(\"next NT step\", i=optimizer_sweep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Parameters\n",
    "From the `gate_map` defined in the Section \"Preparations\", we can directly extract the pulses whose parameters we want to optimize.\n",
    "We exclude the idendity `I` gate here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pulses_to_optimize = {gate_map[k].uid: gate_map[k] for k in gate_map if k != \"I\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we want to optimize the value of `pulse_parameters[\"sigma\"]` for each of these pulses, respectively.\n",
    "We extract the initial parameter values and also set their ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0 = [pulses_to_optimize[k].pulse_parameters[\"sigma\"] for k in pulses_to_optimize]\n",
    "x_range = [(0.0, 0.4) for _ in x_0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To update these parameters during the experiment, we update each pulse with its respective new parameter value and then replace the corresponding pulses in the experiment by them.\n",
    "\n",
    "Note, that updating other parameters like pulse amplitude or even individual waveform samples can be implemented analogously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Near-Time User Callback Function\n",
    "### Objective Function Value\n",
    "We begin by extracting the measurement results at the end of each NT sweep.\n",
    "As each RB sample begins in state 0, we simply average over the measured state indices and use this quantity as objective function value.\n",
    "For other use cases this definition of the objective function value should be adapted.\n",
    "\n",
    "In emulation mode, we will generate synthetic results that decrease during the course of the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function_value(use_emulation):\n",
    "    def f(session: Session, i):\n",
    "        if use_emulation:\n",
    "            # synthetic data decreasing with i\n",
    "            return 0.7 ** (4.0 * i)\n",
    "        else:\n",
    "            # return temporary result\n",
    "            return np.mean(session.results.acquired_results[\"rb_results\"].data[i].real)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, that we use the average state discrimination result directly as objective function value here.\n",
    "Any computational steps needed to evaluate more complex objective functions could be added to this function too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_y = objective_function_value(use_emulation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization Step\n",
    "The following function uses an `Optimizer` instance from the scikit-optimize library to obtain new parameter values for the next optimization step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimization_step(optimizer: Optimizer, x_0):\n",
    "    def f(i, y):\n",
    "        # set x as initial value x_0 or from previous optimization step\n",
    "        last_x = optimizer.ask() if i > 0 else x_0\n",
    "\n",
    "        # update optimizer with new parameter value and objective function result\n",
    "        optimizer.tell(last_x, y)\n",
    "\n",
    "        # ask optimizer for new parameter values and return new and last parameters\n",
    "        return optimizer.ask(), last_x\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, that any Optimizer class can be used here as long as it supports interrupted operation via an ask-and-tell interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an optimizer class supporting ask-and-tell interface\n",
    "optimizer = Optimizer(\n",
    "    dimensions=x_range,\n",
    "    acq_func=\"EI\",\n",
    "    acq_optimizer=\"sampling\",\n",
    "    initial_point_generator=\"lhs\",\n",
    ")\n",
    "\n",
    "# generate optimization step function\n",
    "new_x = optimization_step(\n",
    "    optimizer=optimizer,\n",
    "    x_0=x_0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulse Update\n",
    "We define a collection of pulses as template to apply new parameter values to.\n",
    "The waveforms can then be replaced in the session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pulse_update(pulses):\n",
    "    def f(session: Session, x):\n",
    "        # loop over pulse uids and parameter values\n",
    "        for p, s in zip(pulses, x):\n",
    "            # modify pulse\n",
    "            pulses[p].pulse_parameters[\"sigma\"] = s\n",
    "\n",
    "            # assign modified pulse under the same uid\n",
    "            session.replace_pulse(p, pulses[p])\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize this function with the previously extracted pulses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_x = pulse_update(pulses_to_optimize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Callback Function\n",
    "We can define the user callback function for the NT sweep from the three steps discussed above.\n",
    "Furthermore, the information progress is displayed if convergence is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_NT_step(session: Session, i: float, convergence_criteria=lambda y: y < 1.0e-6):\n",
    "    # optimization step stems from sweep and needs to be converged\n",
    "    ii = int(i)\n",
    "\n",
    "    # evaluate new y from results\n",
    "    y = get_y(session, ii)\n",
    "\n",
    "    # obtain new and old x from optimizer\n",
    "    x, last_x = new_x(ii, y)\n",
    "\n",
    "    # update pulses with new x parameters\n",
    "    set_x(session, x)\n",
    "\n",
    "    # log optimization progress\n",
    "    if ii == 0:\n",
    "        print(f\"\\n{'i': ^6}|{'y': ^12}|{'y': ^12}\")\n",
    "    print(f\"{ii: ^6}| {y:10.2G} |\", \", \".join([f\"{_:8.5f}\" for _ in last_x]))\n",
    "\n",
    "    # convergence check\n",
    "    if convergence_criteria(y):\n",
    "        print(f\"CONVERGED in iteration {ii}\\n\")\n",
    "        session.abort_execution()\n",
    "\n",
    "    return {\"i\": ii, \"y\": y, \"x\": last_x}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device Setup and Session\n",
    "We prepare both the device setup and session objects needed to run the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_db = generate_example_datastore(in_memory=True)\n",
    "device_setup = get_first_named_entry(\n",
    "    db=dummy_db, name=\"6_fixed_qubit_setup_shfqc_calibrated\"\n",
    ")\n",
    "session = Session(device_setup)\n",
    "session.connect(do_emulation=use_emulation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map the experiment signal to logical signals in the device setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.map_signal(\n",
    "    \"drive\", device_setup.logical_signal_groups[\"q0\"].logical_signals[\"drive_line\"]\n",
    ")\n",
    "exp.map_signal(\n",
    "    \"measure\", device_setup.logical_signal_groups[\"q0\"].logical_signals[\"measure_line\"]\n",
    ")\n",
    "exp.map_signal(\n",
    "    \"acquire\", device_setup.logical_signal_groups[\"q0\"].logical_signals[\"acquire_line\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also register the neartime callback function in the session object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.register_neartime_callback(\n",
    "    next_NT_step,\n",
    "    \"next NT step\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Run\n",
    "We can now execute the experiment.\n",
    "In emulation mode we achieve convergence after 10 optimization steps due to the selected convergence criteria and the behavior of the synthetic objective function values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_results = session.run(exp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zi-py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
